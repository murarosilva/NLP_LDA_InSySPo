{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "#!pip install RISparser"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "#!pip install gensim\n",
    "#!pip install nltk\n",
    "#!pip install pprintpp"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "import os\n",
    "from RISparser import readris\n",
    "import gensim\n",
    "from gensim import models\n",
    "import pprint\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from pprint import pprint\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/geopi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "source": [
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "stopwords = set(STOPWORDS)\n",
    "my_stopwords = {'approach','paper','article','model','viewpoint','conclusion','discussion','method','introduction','section','framework','based','result','research',\n",
    "'can','which','from','set','it','we','model','thi','new','use'}\n",
    "all_stopwords = set.union(stopwords,my_stopwords)\n",
    "#all_stopwords = frozenset(my_stopwords)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "data_folder = '/Users/geopi/Documents/Python_Projects/NLP_LDA_InSySPo/NLP_LDA_InSySPo/data/'\n",
    "files = os.listdir(data_folder)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "texts = []\n",
    "titles = []\n",
    "abstracts = []\n",
    "dois = []\n",
    "#lem = WordNetLemmatizer()\n",
    "ps = PorterStemmer()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "source": [
    "for ff in files:\n",
    "    f = data_folder + ff\n",
    "    fid = open(f,'r',encoding=\"utf8\")\n",
    "    data = readris(fid)\n",
    "\n",
    "    for i,entry in enumerate(data):\n",
    "    \n",
    "        try:\n",
    "            title = entry['title']\n",
    "            titles += [title]\n",
    "            abstract = entry['abstract']\n",
    "            abstracts += [abstract]\n",
    "            doi = entry['doi']\n",
    "            dois += [doi]\n",
    "            text = title + ' ' + abstract\n",
    "            text = gensim.utils.simple_preprocess(text)\n",
    "            for i,t in enumerate(text):\n",
    "                text[i] = ps.stem(t)\n",
    "                #text[i] = lem.lemmatize(t)\n",
    "            text = [word for word in text if word not in all_stopwords]\n",
    "            texts += [text]\n",
    "        except:\n",
    "            pass\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "dictionary = gensim.corpora.Dictionary(texts)\n",
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in texts]\n",
    "\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "\n",
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=4, workers=4)\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Topic: 0 \n",
      "Words: 0.026*\"predict\" + 0.019*\"data\" + 0.018*\"machin\" + 0.017*\"learn\" + 0.010*\"classif\" + 0.010*\"perform\" + 0.009*\"classifi\" + 0.008*\"accuraci\" + 0.007*\"wa\" + 0.007*\"select\"\n",
      "Topic: 1 \n",
      "Words: 0.018*\"intellig\" + 0.014*\"technolog\" + 0.014*\"develop\" + 0.013*\"ai\" + 0.012*\"artifici\" + 0.010*\"design\" + 0.010*\"decis\" + 0.009*\"data\" + 0.008*\"applic\" + 0.007*\"support\"\n",
      "Topic: 2 \n",
      "Words: 0.044*\"algorithm\" + 0.032*\"optim\" + 0.026*\"problem\" + 0.018*\"propos\" + 0.011*\"search\" + 0.010*\"solut\" + 0.010*\"perform\" + 0.009*\"network\" + 0.008*\"solv\" + 0.007*\"time\"\n",
      "Topic: 3 \n",
      "Words: 0.034*\"network\" + 0.023*\"data\" + 0.022*\"neural\" + 0.018*\"learn\" + 0.014*\"artifici\" + 0.012*\"deep\" + 0.011*\"intellig\" + 0.009*\"forecast\" + 0.009*\"predict\" + 0.009*\"techniqu\"\n",
      "Topic: 4 \n",
      "Words: 0.031*\"imag\" + 0.016*\"featur\" + 0.014*\"propos\" + 0.012*\"detect\" + 0.010*\"recognit\" + 0.008*\"segment\" + 0.008*\"algorithm\" + 0.007*\"object\" + 0.007*\"data\" + 0.006*\"perform\"\n",
      "Topic: 5 \n",
      "Words: 0.015*\"knowledg\" + 0.012*\"fuzzi\" + 0.010*\"inform\" + 0.009*\"gener\" + 0.009*\"rule\" + 0.008*\"data\" + 0.008*\"reason\" + 0.007*\"process\" + 0.007*\"propos\" + 0.007*\"problem\"\n",
      "Topic: 6 \n",
      "Words: 0.012*\"agent\" + 0.010*\"time\" + 0.010*\"network\" + 0.009*\"propos\" + 0.008*\"control\" + 0.008*\"oper\" + 0.008*\"intellig\" + 0.008*\"energi\" + 0.007*\"data\" + 0.007*\"environ\"\n",
      "Topic: 7 \n",
      "Words: 0.024*\"learn\" + 0.014*\"human\" + 0.012*\"intellig\" + 0.011*\"comput\" + 0.009*\"artifici\" + 0.007*\"cognit\" + 0.007*\"interact\" + 0.007*\"machin\" + 0.007*\"robot\" + 0.006*\"game\"\n",
      "Topic: 8 \n",
      "Words: 0.026*\"control\" + 0.011*\"artifici\" + 0.011*\"neural\" + 0.011*\"network\" + 0.010*\"process\" + 0.009*\"intellig\" + 0.008*\"design\" + 0.008*\"wa\" + 0.008*\"paramet\" + 0.007*\"time\"\n",
      "Topic: 9 \n",
      "Words: 0.017*\"patient\" + 0.014*\"wa\" + 0.012*\"clinic\" + 0.011*\"imag\" + 0.010*\"diseas\" + 0.008*\"studi\" + 0.008*\"diagnosi\" + 0.008*\"cancer\" + 0.008*\"predict\" + 0.008*\"learn\"\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "teste = 1500\n",
    "for index, score in sorted(lda_model[bow_corpus[teste]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic ({}): {}\".format(score, index, lda_model.print_topic(index, 10)))\n",
    "\n",
    "print('\\nTitle:{}\\nAbs: {}\\nDoi: {}'.format(titles[teste], abstracts[teste], dois[teste]))\n",
    "print(texts[teste-2])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Score: 0.44684991240501404\t \n",
      "Topic (1): 0.018*\"intellig\" + 0.014*\"technolog\" + 0.014*\"develop\" + 0.013*\"ai\" + 0.012*\"artifici\" + 0.010*\"design\" + 0.010*\"decis\" + 0.009*\"data\" + 0.008*\"applic\" + 0.007*\"support\"\n",
      "\n",
      "Score: 0.43455541133880615\t \n",
      "Topic (7): 0.024*\"learn\" + 0.014*\"human\" + 0.012*\"intellig\" + 0.011*\"comput\" + 0.009*\"artifici\" + 0.007*\"cognit\" + 0.007*\"interact\" + 0.007*\"machin\" + 0.007*\"robot\" + 0.006*\"game\"\n",
      "\n",
      "Score: 0.10265827924013138\t \n",
      "Topic (3): 0.034*\"network\" + 0.023*\"data\" + 0.022*\"neural\" + 0.018*\"learn\" + 0.014*\"artifici\" + 0.012*\"deep\" + 0.011*\"intellig\" + 0.009*\"forecast\" + 0.009*\"predict\" + 0.009*\"techniqu\"\n",
      "\n",
      "Title:Diffuse large B-cell lymphoma outcome prediction by gene-expression profiling and supervised machine learning\n",
      "Abs: Usually, a proof of a theorem contains more knowledge than the mere fact that the theorem is true. For instance, to prove that a graph is Hamiltonian it suffices to exhibit a Hamiltonian tour in it; however, this seems to contain more knowledge than the single bit Hamiltonian/non-Hamiltonian. In this paper a computational complexity theory of the 'knowledge' contained in a proof is developed. Zero-knowledge proofs are defined as those proofs that convey no additional knowledge other than the correctness of the proposition in question. Examples of zero-knowledge proof systems are given for the languages of quadratic residuosity and quadratic nonresiduosity. These are the first examples of zero-knowledge proofs for languages not known to be efficiently recognizable.\n",
      "Doi: 10.1002/rob.20147\n",
      "['diffus', 'larg', 'cell', 'lymphoma', 'outcom', 'predict', 'gene', 'express', 'profil', 'supervis', 'machin', 'learn', 'diffus', 'larg', 'cell', 'lymphoma', 'dlbcl', 'common', 'lymphoid', 'malign', 'adult', 'curabl', 'patient', 'prognost', 'base', 'pre', 'treatment', 'characterist', 'intern', 'prognost', 'index', 'ipi', 'current', 'predict', 'outcom', 'dlbcl', 'howev', 'clinic', 'outcom', 'identifi', 'molecular', 'basi', 'clinic', 'heterogen', 'specif', 'therapeut', 'target', 'analyz', 'express', 'gene', 'diagnost', 'tumor', 'specimen', 'dlbcl', 'patient', 'receiv', 'adriamycin', 'vincristin', 'prednison', 'chop', 'base', 'chemotherapi', 'appli', 'supervis', 'learn', 'predict', 'identifi', 'cure', 'versu', 'fatal', 'refractori', 'diseas', 'algorithm', 'classifi', 'categori', 'patient', 'veri', 'differ', 'year', 'overal', 'surviv', 'rate', 'versu', 'effect', 'delin', 'patient', 'specif', 'ipi', 'risk', 'categori', 'like', 'cure', 'die', 'diseas', 'gene', 'implic', 'dlbcl', 'outcom', 'includ', 'regul', 'respons', 'cell', 'receptor', 'signal', 'critic', 'serin', 'threonin', 'phosphoryl', 'pathway', 'apoptosi', 'data', 'indic', 'supervis', 'learn', 'classif', 'techniqu', 'predict', 'outcom', 'dlbcl', 'identifi', 'ration', 'target', 'intervent', 'natur', 'publish', 'group']\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "len() takes exactly one argument (4 given)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-c413ec548300>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nTitle:{}\\nAbs: {}\\nDoi: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mteste\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabstracts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mteste\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdois\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mteste\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mteste\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabstracts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdois\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: len() takes exactly one argument (4 given)"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "source": [
    "print(len(titles),' ',len(abstracts),' ',len(dois),' ',len(texts))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "127573   124185   108657   108657\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "source": [
    "new_doc = 'Piriri pororó'\n",
    "\n",
    "bow_vector = dictionary.doc2bow(preprocess(new_doc))\n",
    "for index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "    print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, 5)))"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'preprocess' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-7f4bf1bbb411>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnew_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Piriri pororó'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbow_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc2bow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_doc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlda_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbow_vector\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Score: {}\\t Topic: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlda_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_topic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preprocess' is not defined"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "dcd6b6c39f38cba9f8c72230f33624d8dccb377e8b332ffe19b0c643a7d25c1c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}