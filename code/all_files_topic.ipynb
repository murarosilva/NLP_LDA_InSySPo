{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\r\n",
    "from RISparser import readris\r\n",
    "import gensim\r\n",
    "from gensim import models\r\n",
    "import pprint\r\n",
    "from nltk.stem import WordNetLemmatizer\r\n",
    "from pprint import pprint"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from gensim.parsing.preprocessing import STOPWORDS\r\n",
    "stopwords = set(STOPWORDS)\r\n",
    "my_stopwords = {'approach','paper','article','model','viewpoint','conclusion','discussion','method','introduction','section','framework','based','result','proposed','theory','information','process','analysis','data','problem','review','springer','verlag'}\r\n",
    "my_stopwords = set.union(stopwords,my_stopwords)\r\n",
    "my_stopwords = frozenset(my_stopwords)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "data_folder = 'D:/Pesquisa/NLP_LDA_InSySPo/data/'\r\n",
    "files = os.listdir(data_folder)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "texts = []\r\n",
    "dois = []\r\n",
    "author_address = []\r\n",
    "publication_year = []\r\n",
    "lem = WordNetLemmatizer()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "for ff in files:\r\n",
    "    f = data_folder + ff\r\n",
    "    fid = open(f,'r',encoding=\"utf8\")\r\n",
    "    data = readris(fid)\r\n",
    "\r\n",
    "    for i,entry in enumerate(data):\r\n",
    "    \r\n",
    "        try:\r\n",
    "            title = entry['title']\r\n",
    "            abstract = entry['abstract']\r\n",
    "            \r\n",
    "            if 'doi' in entry:\r\n",
    "                dois += [entry['doi']]\r\n",
    "            else:\r\n",
    "                dois += [['']]\r\n",
    "\r\n",
    "            if 'author_address' in entry:\r\n",
    "                country = entry['author_address'].split(',')[-1]\r\n",
    "                if country[0] == ' ':\r\n",
    "                    country = country[1:]\r\n",
    "                author_address += [country]\r\n",
    "            else:\r\n",
    "                author_address += ['-']\r\n",
    "\r\n",
    "            if 'publication_year' in entry:\r\n",
    "                publication_year += [entry['publication_year']]\r\n",
    "            else:\r\n",
    "                publication_year += ['-']\r\n",
    "\r\n",
    "            text = title + ' ' + abstract\r\n",
    "            text = gensim.utils.simple_preprocess(text)\r\n",
    "            for i,t in enumerate(text):\r\n",
    "                text[i] = lem.lemmatize(t)\r\n",
    "\r\n",
    "            text = [word for word in text if word not in my_stopwords]\r\n",
    "\r\n",
    "            texts += [text]\r\n",
    "\r\n",
    "        except:\r\n",
    "            pass\r\n",
    "\r\n",
    "    fid.close()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "source": [
    "dictionary = gensim.corpora.Dictionary(texts)\r\n",
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\r\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in texts]\r\n",
    "\r\n",
    "tfidf = models.TfidfModel(bow_corpus)\r\n",
    "corpus_tfidf = tfidf[bow_corpus]\r\n",
    "\r\n",
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=20, id2word=dictionary, passes=4, workers=4)\r\n",
    "for idx, topic in lda_model.print_topics(-1):\r\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Topic: 0 \n",
      "Words: 0.026*\"decision\" + 0.014*\"support\" + 0.013*\"management\" + 0.011*\"agent\" + 0.010*\"system\" + 0.009*\"process\" + 0.008*\"making\" + 0.008*\"student\" + 0.008*\"service\" + 0.007*\"study\"\n",
      "Topic: 1 \n",
      "Words: 0.028*\"game\" + 0.025*\"agent\" + 0.016*\"virtual\" + 0.016*\"learning\" + 0.010*\"behavior\" + 0.008*\"player\" + 0.007*\"training\" + 0.007*\"team\" + 0.007*\"software\" + 0.006*\"environment\"\n",
      "Topic: 2 \n",
      "Words: 0.028*\"rule\" + 0.021*\"logic\" + 0.020*\"reasoning\" + 0.018*\"theory\" + 0.016*\"fuzzy\" + 0.015*\"system\" + 0.010*\"representation\" + 0.010*\"knowledge\" + 0.009*\"inference\" + 0.009*\"model\"\n",
      "Topic: 3 \n",
      "Words: 0.022*\"human\" + 0.013*\"health\" + 0.011*\"intelligence\" + 0.011*\"artificial\" + 0.009*\"robot\" + 0.007*\"care\" + 0.007*\"study\" + 0.007*\"cognitive\" + 0.006*\"covid\" + 0.006*\"social\"\n",
      "Topic: 4 \n",
      "Words: 0.055*\"network\" + 0.017*\"detection\" + 0.017*\"data\" + 0.014*\"fault\" + 0.013*\"sensor\" + 0.011*\"neural\" + 0.011*\"proposed\" + 0.011*\"time\" + 0.009*\"monitoring\" + 0.007*\"learning\"\n",
      "Topic: 5 \n",
      "Words: 0.033*\"knowledge\" + 0.022*\"expert\" + 0.021*\"system\" + 0.020*\"design\" + 0.012*\"language\" + 0.012*\"information\" + 0.011*\"process\" + 0.008*\"application\" + 0.008*\"data\" + 0.007*\"tool\"\n",
      "Topic: 6 \n",
      "Words: 0.030*\"user\" + 0.015*\"information\" + 0.012*\"web\" + 0.012*\"text\" + 0.011*\"data\" + 0.010*\"mining\" + 0.009*\"result\" + 0.009*\"content\" + 0.009*\"social\" + 0.009*\"analysis\"\n",
      "Topic: 7 \n",
      "Words: 0.044*\"image\" + 0.021*\"recognition\" + 0.015*\"feature\" + 0.012*\"object\" + 0.008*\"proposed\" + 0.008*\"pattern\" + 0.008*\"visual\" + 0.007*\"shape\" + 0.007*\"algorithm\" + 0.007*\"motion\"\n",
      "Topic: 8 \n",
      "Words: 0.021*\"model\" + 0.021*\"prediction\" + 0.017*\"data\" + 0.014*\"network\" + 0.014*\"neural\" + 0.012*\"machine\" + 0.012*\"artificial\" + 0.011*\"result\" + 0.010*\"study\" + 0.010*\"ann\"\n",
      "Topic: 9 \n",
      "Words: 0.027*\"patient\" + 0.021*\"clinical\" + 0.021*\"diagnosis\" + 0.017*\"medical\" + 0.014*\"cancer\" + 0.012*\"disease\" + 0.011*\"diagnostic\" + 0.009*\"treatment\" + 0.009*\"study\" + 0.008*\"ai\"\n",
      "Topic: 10 \n",
      "Words: 0.057*\"problem\" + 0.015*\"algorithm\" + 0.014*\"constraint\" + 0.014*\"solution\" + 0.014*\"search\" + 0.012*\"springer\" + 0.010*\"solving\" + 0.010*\"graph\" + 0.010*\"verlag\" + 0.009*\"case\"\n",
      "Topic: 11 \n",
      "Words: 0.029*\"intelligence\" + 0.026*\"ai\" + 0.026*\"artificial\" + 0.022*\"technology\" + 0.021*\"data\" + 0.020*\"research\" + 0.015*\"application\" + 0.012*\"development\" + 0.010*\"review\" + 0.009*\"field\"\n",
      "Topic: 12 \n",
      "Words: 0.024*\"fuzzy\" + 0.018*\"function\" + 0.014*\"set\" + 0.009*\"value\" + 0.008*\"measure\" + 0.008*\"decision\" + 0.008*\"probability\" + 0.007*\"proposed\" + 0.007*\"criterion\" + 0.007*\"analysis\"\n",
      "Topic: 13 \n",
      "Words: 0.055*\"network\" + 0.043*\"neural\" + 0.028*\"learning\" + 0.026*\"deep\" + 0.013*\"memory\" + 0.012*\"architecture\" + 0.010*\"artificial\" + 0.008*\"processing\" + 0.007*\"performance\" + 0.007*\"convolutional\"\n",
      "Topic: 14 \n",
      "Words: 0.088*\"control\" + 0.021*\"controller\" + 0.015*\"system\" + 0.015*\"time\" + 0.014*\"dynamic\" + 0.013*\"action\" + 0.011*\"simulation\" + 0.011*\"adaptive\" + 0.010*\"process\" + 0.010*\"state\"\n",
      "Topic: 15 \n",
      "Words: 0.011*\"image\" + 0.009*\"study\" + 0.008*\"classification\" + 0.008*\"analysis\" + 0.007*\"result\" + 0.007*\"accuracy\" + 0.007*\"data\" + 0.007*\"patient\" + 0.006*\"segmentation\" + 0.006*\"method\"\n",
      "Topic: 16 \n",
      "Words: 0.044*\"algorithm\" + 0.030*\"optimization\" + 0.016*\"problem\" + 0.014*\"proposed\" + 0.010*\"ant\" + 0.009*\"colony\" + 0.009*\"time\" + 0.009*\"solution\" + 0.008*\"optimal\" + 0.008*\"swarm\"\n",
      "Topic: 17 \n",
      "Words: 0.035*\"learning\" + 0.030*\"data\" + 0.020*\"algorithm\" + 0.018*\"classification\" + 0.018*\"feature\" + 0.012*\"proposed\" + 0.010*\"set\" + 0.010*\"machine\" + 0.010*\"classifier\" + 0.010*\"method\"\n",
      "Topic: 18 \n",
      "Words: 0.019*\"protein\" + 0.015*\"gene\" + 0.011*\"prediction\" + 0.011*\"sequence\" + 0.010*\"drug\" + 0.010*\"machine\" + 0.009*\"data\" + 0.009*\"cell\" + 0.008*\"method\" + 0.008*\"structure\"\n",
      "Topic: 19 \n",
      "Words: 0.020*\"power\" + 0.019*\"energy\" + 0.011*\"material\" + 0.010*\"artificial\" + 0.008*\"intelligence\" + 0.008*\"process\" + 0.007*\"high\" + 0.006*\"sensor\" + 0.005*\"temperature\" + 0.005*\"device\"\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "topics = []\r\n",
    "scores = []\r\n",
    "for ind_doc, bc in enumerate(bow_corpus):\r\n",
    "    ind_top, score = sorted(lda_model[bc], key=lambda tup: -1*tup[1])[0]\r\n",
    "    topics += [ind_top]\r\n",
    "    scores += [score]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "ind_doc = 6\r\n",
    "topics[ind_doc]\r\n",
    "scores[ind_doc]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.29752576"
      ]
     },
     "metadata": {},
     "execution_count": 87
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "source": [
    "teste = 450\r\n",
    "print('\\nTitle & Abs: {}\\Country: {}\\nDOI:{}\\nTopic: {} - Score: {}\\n'.format(texts[teste], author_address[teste], dois[teste], topics[teste], scores[teste]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Title & Abs: ['vlsi', 'implementation', 'fuzzy', 'inference', 'engine', 'expert', 'chip', 'present', 'vlsi', 'implementation', 'inference', 'mechanism', 'cope', 'uncertainty', 'perform', 'approximate', 'reasoning', 'design', 'max', 'min', 'operation', 'fuzzy', 'set', 'theory', 'effective', 'real', 'time', 'use', 'inference', 'mechanism', 'handle', 'imprecise', 'uncertain', 'knowledge', 'obtain', 'human', 'expert', 'knowledge', 'simulate', 'reasoning', 'process', 'inference', 'mechanism', 'realized', 'custom', 'cmos', 'technology', 'emphasizes', 'simplicity', 'extensibility', 'efficiency', 'timing', 'simulation', 'suggests', 'inference', 'engine', 'perform', 'approximately', 'fuzzy', 'logical', 'inference', 'second', 'potential', 'application', 'inference', 'engine', 'real', 'time', 'decision', 'making', 'area', 'command', 'control', 'adaptive', 'command', 'generation', 'robotic', 'system']\\Country: United States\n",
      "DOI:10.1016/0020-0255(86)90017-4\n",
      "Topic: 2 - Score: 0.3471664488315582\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "source": [
    "print(len(topics),len(author_address),len(texts),len(dois))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "248368 245262 248368 248370\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "ind_doc = 430\r\n",
    "for index, score in sorted(lda_model[bow_corpus[ind_doc]], key=lambda tup: -1*tup[1]):\r\n",
    "    print(\"\\nScore: {}\\t \\nTopic ({}): {}\".format(score, index, lda_model.print_topic(index, 10)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Score: 0.5360517501831055\t \n",
      "Topic (8): 0.042*\"algorithm\" + 0.016*\"problem\" + 0.014*\"proposed\" + 0.013*\"optimization\" + 0.011*\"search\" + 0.008*\"result\" + 0.008*\"space\" + 0.007*\"local\" + 0.007*\"performance\" + 0.006*\"swarm\"\n",
      "\n",
      "Score: 0.1691380739212036\t \n",
      "Topic (2): 0.051*\"image\" + 0.023*\"recognition\" + 0.018*\"object\" + 0.013*\"human\" + 0.012*\"sensor\" + 0.011*\"visual\" + 0.009*\"vision\" + 0.008*\"video\" + 0.008*\"feature\" + 0.008*\"motion\"\n",
      "\n",
      "Score: 0.12600445747375488\t \n",
      "Topic (10): 0.036*\"feature\" + 0.033*\"classification\" + 0.025*\"machine\" + 0.024*\"learning\" + 0.019*\"classifier\" + 0.016*\"data\" + 0.015*\"algorithm\" + 0.014*\"accuracy\" + 0.014*\"vector\" + 0.012*\"performance\"\n",
      "\n",
      "Score: 0.10859081894159317\t \n",
      "Topic (15): 0.029*\"gene\" + 0.022*\"brain\" + 0.013*\"expression\" + 0.013*\"signal\" + 0.009*\"analysis\" + 0.009*\"subject\" + 0.008*\"study\" + 0.008*\"data\" + 0.007*\"eeg\" + 0.006*\"pattern\"\n",
      "\n",
      "Score: 0.04393729940056801\t \n",
      "Topic (13): 0.034*\"learning\" + 0.034*\"segmentation\" + 0.014*\"reinforcement\" + 0.009*\"channel\" + 0.008*\"image\" + 0.008*\"noise\" + 0.008*\"quantum\" + 0.008*\"algorithm\" + 0.007*\"device\" + 0.006*\"performance\"\n",
      "\n",
      "Score: 0.010792764835059643\t \n",
      "Topic (4): 0.023*\"protein\" + 0.013*\"sequence\" + 0.012*\"prediction\" + 0.012*\"cell\" + 0.010*\"structure\" + 0.009*\"drug\" + 0.007*\"method\" + 0.007*\"machine\" + 0.006*\"interaction\" + 0.006*\"learning\"\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "len(bow_corpus)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'bow_corpus' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-fb2a39be5e85>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbow_corpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'bow_corpus' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "07efdcd4b820c98a756949507a4d29d7862823915ec7477944641bea022f4f62"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}